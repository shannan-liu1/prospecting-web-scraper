{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. First time user? Run this first to download the relevant functionality for the program "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otherwise, *skip*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install selenium\n",
    "%pip install parsel\n",
    "%pip install time\n",
    "%pip install pandas\n",
    "%pip install bs4\n",
    "%pip install urllib\n",
    "%pip install request\n",
    "%pip install numpy\n",
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run this to import relevant functionality for the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import selenium\n",
    "import parsel\n",
    "import time\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "from parsel import Selector\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from openpyxl import load_workbook\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Chrome Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link:\n",
    "https://chromedriver.chromium.org/downloads\n",
    "- make sure you download the chromedriver that is compatible with your google chrome version\n",
    "- check you google chrome version by clicking three dots on top right of the Google Chrome browser > Help > About Google Chrome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Open Chrome Driver & LinkedIn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set 'path' as the file pathway to where Chrome Driver is stored on your device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'G:\\Sales-Shared\\- CPA\\LinkedIn Prospecting\\chromedriver_win32/chromedriver.exe'\n",
    "driver = webdriver.Chrome(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will take the user to LinkedIn\n",
    "# Please login\n",
    "driver.get('https://www.linkedin.com/sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your LinkedIn credentials and then enter a search query on Sales Navigator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've entered your search query and LinkedIn Sales Navigator has generated a list of leads on your screen, you can proceed to the code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Familiarise yourself with the following functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to know functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"Functions\" begin with \"def\" (in green in the code blocks below). These 2 functions in particular require user input and understanding:**\n",
    "- **get_page_links_all(num_pages)**\n",
    "    - purpose: returns a list of user profile links on a specified number of search result pages; runs chronologically\n",
    "    - **requried user input:** number of search result pages, 'num_pages', you want to obtain user profile links from\n",
    "        - if no input is specified, the function fails; the function doesn't default to collecting links on all of the pages in the search query if nothing is specified\n",
    "    - example: if you wanted to scrape LinkedIn data on 14 pages, you would type in 14 between the parentheses like this: get_page_links_all(14)\n",
    "- **get_all_data(links,file_name)**\n",
    "    - purpose: scrapes profile data from all the links fed into it and saves that data into an excel file\n",
    "        - profile data includes: name, location, company, role, a bio, and the user's LinkedIn url\n",
    "        - links is the list of linkes you collected by using the \"get_page_links_all()\" function\n",
    "        - 'file_name' is the name of the excel file you want the data saved into\n",
    "    - **required user input:** list of links, 'links', and the name of the excel file, 'file_name' you want to store your data into\n",
    "    - example: get_all_data(proper_links,'prospect file 1.xlsx')\n",
    "\n",
    "**You can ignore all other functions. But if you're curious, you can continue reading the documentation below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_links():\n",
    "    \"\"\"\n",
    "    Returns a list of the unique user profile links from a single page of a search query on Sales Navigator. \n",
    "    \n",
    "    The function will scroll down the search page collecting links because the links on\n",
    "    Sales Navigator do not load until they are shown on screen. \n",
    "    \"\"\"\n",
    "    \n",
    "    sel = Selector(text=driver.page_source)\n",
    "    good_links = []\n",
    "    \n",
    "    y = 0\n",
    "    for timer in range(0,12):\n",
    "        sleep(1)\n",
    "        driver.execute_script(\"window.scrollTo(0, \"+str(y)+\")\")\n",
    "        y += 500 \n",
    "    \n",
    "    all_links = driver.find_elements_by_tag_name('a')\n",
    "    for link in all_links:\n",
    "        if link.get_attribute('href').startswith('https://www.linkedin.com/sales/people/'):\n",
    "            good_links.append(link.get_attribute('href'))\n",
    "    return (list(set(good_links))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_links_all(num_pages):\n",
    "    \"\"\"\n",
    "    Returns a list of unique user profile links from a specified number of pages of a search query on Sales Navigator. \n",
    "    \n",
    "    The function collect links over a certain number of pages. Once done with the current \n",
    "    page, the function will click the \"Next\" button to move on to the next page and \n",
    "    scrape those links (and so on).\n",
    "    \n",
    "    If you do not specify a the number of pages you want to scrape data from, the function\n",
    "    will return an error. If you specify a number of pages in excess of the number of \n",
    "    search result pages generated, then the function will also return an error.\n",
    "    \"\"\"\n",
    "    links = []\n",
    "    for i in range(0,num_pages):\n",
    "        sleep(0.2)\n",
    "        \n",
    "        sel = Selector(text=driver.page_source)\n",
    "        \n",
    "        y = 200\n",
    "        for timer in range(0,12):\n",
    "            sleep(0.2)\n",
    "            driver.execute_script(\"window.scrollTo(0, \"+str(y)+\")\")\n",
    "            y += 500  \n",
    "             \n",
    "        for link in driver.find_elements_by_tag_name('a'):\n",
    "            if link.get_attribute('href').startswith('https://www.linkedin.com/sales/people/'):\n",
    "                links.append(link.get_attribute('href'))\n",
    "\n",
    "        sleep(1)\n",
    "        button = driver.find_element_by_class_name('search-results__pagination-next-button')\n",
    "        \n",
    "        if button.click() != None:\n",
    "            button.click()\n",
    "                     \n",
    "    return list(set(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_data_point():\n",
    "    \n",
    "    \"\"\"\n",
    "    Obtains a single user's name, role & firm, location, and self-bio from their Sales Navigator user profile page.\n",
    "    \n",
    "    Appends that information to the following lists:\n",
    "    names = [] (stores the user's name)\n",
    "    roles_and_firms = [] (stores the user's role & firm)\n",
    "    locations = [] (stores the user's location)\n",
    "    abouts = [] (stores the user's self-bio)\n",
    "    \n",
    "    Please initialise these lists before using this function.\n",
    "    \"\"\"\n",
    "    \n",
    "    sleep(1)\n",
    "    # get names\n",
    "    potential_name_block = driver.find_elements_by_tag_name('span')\n",
    "    for name in potential_name_block:\n",
    "        if name.get_attribute('class').startswith('profile-topcard-person-entity__name'):\n",
    "            names.append(name.text)\n",
    "    \n",
    "    sleep(0.5)\n",
    "    # get titles\n",
    "    potential_title_block = driver.find_elements_by_tag_name('dd')\n",
    "    for title in potential_title_block:\n",
    "        if title.get_attribute('class').startswith('mt2'):\n",
    "            roles_and_firms.append(title.text)\n",
    "    \n",
    "    sleep(0.5)\n",
    "    # get locations\n",
    "    potential_location_block = driver.find_elements_by_tag_name('div')\n",
    "    for location in potential_location_block:\n",
    "        if location.get_attribute('class').startswith('profile-topcard__location'):\n",
    "            locations.append(location.text)\n",
    "            \n",
    "    sleep(0.5)\n",
    "    # get more info\n",
    "    # click 'see more' button first\n",
    "    potential_see_more_button = driver.find_elements_by_tag_name('button')\n",
    "    for button in potential_see_more_button:\n",
    "        if button.get_attribute('class').startswith('button--unstyled link-without-visited-state inline-block'):\n",
    "            if button.click() != None:\n",
    "                sleep(1)\n",
    "                button.click()\n",
    "    \n",
    "    potential_about_block = driver.find_elements_by_tag_name('div')\n",
    "    for about in potential_about_block:\n",
    "        if about.get_attribute('class').startswith('profile-topcard__summary-modal-content'):\n",
    "            if len(about.text) > 0:\n",
    "                abouts.append(about.text)\n",
    "            else:\n",
    "                potential_about_block = driver.find_elements_by_tag_name('span')\n",
    "                for about in potential_about_block:\n",
    "                    if about.get_attribute('class').startswith('display-block overflow-hidden profile-topcard__summary-content'):\n",
    "                        abouts.append(about.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(links,file_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    Stores multiple users' names, roles & firms, locations, self-bios, and urls into a \n",
    "    user specified Excel file\n",
    "    \n",
    "    This function accepts a list of links which you can collect \n",
    "    via the get_page_links_all(num_pages) function and an existing Excel file's name.\n",
    "    \n",
    "    The function will also show the user a progress counter for the number of results \n",
    "    that have been collected.\n",
    "    \n",
    "    Example: \n",
    "    proper_links = get_page_links_all(12)\n",
    "    get_all_data(proper_links,'prospect list 1.xlsx')\n",
    "    \"\"\"\n",
    "    \n",
    "    workbook = load_workbook(file_name)\n",
    "    worksheet = workbook.worksheets[0]\n",
    "    \n",
    "    counter = 1\n",
    "    for i in range(0,len(links)):\n",
    "        driver.get(links[i])\n",
    "        \n",
    "        sleep(1)\n",
    "        get_single_data_point()\n",
    "        \n",
    "        if len(names) > 0:\n",
    "            worksheet[f'b{i+2}'] = (names.pop())\n",
    "        else:\n",
    "            worksheet[f'b{i+2}'] = (None)\n",
    "            \n",
    "        if len(roles_and_firms) > 0:\n",
    "            worksheet[f'c{i+2}'] = (roles_and_firms.pop())\n",
    "        else:\n",
    "            worksheet[f'c{i+2}'] = (None)\n",
    "            \n",
    "        if len(locations) > 0:\n",
    "            worksheet[f'd{i+2}'] = (locations.pop())\n",
    "        else: \n",
    "            worksheet[f'd{i+2}'] = (None)\n",
    "        \n",
    "        if len(abouts) > 0:\n",
    "            worksheet[f'e{i+2}'] = (abouts.pop())\n",
    "        else:\n",
    "            worksheet[f'e{i+2}'] = (None)\n",
    "        \n",
    "        worksheet[f'f{i+2}'] = (driver.current_url)\n",
    "        \n",
    "        print(f\"Progress: {counter} / {len(links)}\")\n",
    "        counter += 1\n",
    "        \n",
    "        workbook.save(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Web Scraping on LinkedIn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CAUTION:*** remember to have your search query results up before running any of the code below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Collect the links of prospects' Sales Navigator profiles\n",
    "2. Save these links to an Excel file for future reference\n",
    "3. Collect user profile data and save that to an Excel file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get all relevant links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list to store links\n",
    "proper_links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get x pages of links\n",
    "proper_links = get_page_links_all(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many links we scraped from all pages; there should be 25 links per full page\n",
    "len(proper_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 I'd recommend saving the list of links you've collected to an Excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With the following blocks of code below, you can save the list of links that you've collected to an Excel file \n",
    "- This is useful because when you close this program (i.e. close this tab in Google Chrome), the list of links stored in the \"proper_links\" variable will need to be collected again\n",
    "- By saving your links, you won't need to scrape the data again; instead, you can just load it from the excel file you saved your links in\n",
    "- make the file name informative like: \"Prospects from Google.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df = pd.DataFrame(proper_links,columns = ['urls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How code block below works:\n",
    "1. **links_df.to_excel(\"links.xlsx\",sheet_name='URLs', columns=links_df.columns)**\n",
    "    - creates a new Excel file with the name \"links.xlsx\" \n",
    "    - YOU CAN CHANGE the name of \"links.xlsx\" to create a NEW Excel file, with an informative name\n",
    "    - if you already have a file called \"links.xlsx\", running this block of code may override your original file or produce an error message \n",
    "    - ALWAYS KEEP \".xlsx\" in the name, otherwise you'll get an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df.to_excel(\"Biotech Prospect Links.xlsx\",sheet_name='URLs', columns=links_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load up links from an Excel file you've saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_links = pd.read_excel(\"Biotech Prospect Links.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_links = list(load_links['urls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scrape data from Sales Navigator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How the code block below works:\n",
    "1. **final_df = pd.DataFrame(columns = ['names','role & firm','location','about','urls'])**\n",
    "    - creates a new dataframe in Python -- you **CAN IGNORE** \n",
    "2. **final_df.to_excel(\"output_digital_transformation.xlsx\",sheet_name='Prospect Info', columns=final_df.columns)**\n",
    "    - creates a new Excel file with the name \"Biotech Prospects\" \n",
    "    - note: *you can change* \"Biotech Prospects.xlsx\" to create a new Excel file with a different name\n",
    "    - if you already have a file called \"Biotech Prospects.xlsx\", running this block of code may override your original file OR produce an error\n",
    "    - ALWAYS KEEP \".xlsx\" in the name, otherwise you'll get an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns = ['names','role & firm','location','about','urls'])\n",
    "final_df.to_excel(\"Biotech Prospects.xlsx\",sheet_name='Prospect Info', columns=final_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS to instatiate the lists necessary to collect our data from LinkedIn\n",
    "# data to extract\n",
    "names = []\n",
    "roles_and_firms = []\n",
    "locations = []\n",
    "abouts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_all_data((proper_links),\"Biotech Prospects.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT EXTRA NOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes get_all_data((proper_links),\"file_name.xlsx\") outputs an **error** while executing, but do not fret: get_all_data((proper_links),\"file_name.xlsx\") **autosaves** information in Excel while executing, so **you will retain all data scraped up to the point of failure.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: if get_all_data((proper_links),\"file_name.xlsx\") breaks at 195/300; I will still have 195 data points on user profiles\n",
    "\n",
    "To get the remaining data, you can: \n",
    "- create a new excel file (with a different name) via the following code:\n",
    "    - final_df = pd.DataFrame(columns = ['names','role & firm','location','about','urls'])\n",
    "    - final_df.to_excel(\"file_name_2.xlsx\",sheet_name='Prospect Info', columns=final_df.columns)\n",
    "- then run this final line of code to collect the rest of the info:\n",
    "    - get_all_data((proper_links[196:300]),\"file_name_2.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your team's sales people cover different regions, roles, or firms, you can develop functionality on top of this tool to group and organise prospects by these attributes. This will improve your team's prospecting process because it will:\n",
    "1. Help you analyse the number of prospects per region/firm/role and therefore give the team a better idea of how to split the prospects across different team members\n",
    "2. Increase your team's efficiency because it will help each person find their respective list of targets more efficienctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_prospects = pd.read_excel('Sustainability Prospects in Canada.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_prospects = canada_prospects.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 650 entries, 0 to 649\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   names        650 non-null    object\n",
      " 1   role & firm  650 non-null    object\n",
      " 2   location     650 non-null    object\n",
      " 3   about        472 non-null    object\n",
      " 4   urls         650 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 25.5+ KB\n"
     ]
    }
   ],
   "source": [
    "canada_prospects.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>role &amp; firm</th>\n",
       "      <th>location</th>\n",
       "      <th>about</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gilbert Sabat</td>\n",
       "      <td>Digital Evangelist and Organization Evolution ...</td>\n",
       "      <td>Oakville, Ontario, Canada</td>\n",
       "      <td>I have 21 years of experience in the transform...</td>\n",
       "      <td>https://www.linkedin.com/sales/people/ACwAAADC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patrick Li</td>\n",
       "      <td>Vice President Of Engineering at KioSoft Techn...</td>\n",
       "      <td>Greater Toronto Area, Canada</td>\n",
       "      <td>Patrick's current focus is on coaching and tra...</td>\n",
       "      <td>https://www.linkedin.com/sales/people/ACwAAACT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siraj Berhan, MBA, Certified Enterprise Coach</td>\n",
       "      <td>Director, Agile Enablement | Championing for a...</td>\n",
       "      <td>Toronto, Ontario, Canada</td>\n",
       "      <td>Over 17 years of progressive software developm...</td>\n",
       "      <td>https://www.linkedin.com/sales/people/ACwAAAAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ed Norrena</td>\n",
       "      <td>Pres and CEO at EDGE Environmental Consulting LTD</td>\n",
       "      <td>Ottawa, Ontario, Canada</td>\n",
       "      <td>Ed Norrena is a civil engineer/executive with ...</td>\n",
       "      <td>https://www.linkedin.com/sales/people/ACwAAAO4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natasha Walji</td>\n",
       "      <td>Director @ Google | McKinsey | Yale | Cambridg...</td>\n",
       "      <td>Toronto, Ontario, Canada</td>\n",
       "      <td>Director at Google leading the Telecom, Tech &amp;...</td>\n",
       "      <td>https://www.linkedin.com/sales/people/ACwAAAAG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           names  \\\n",
       "0                                  Gilbert Sabat   \n",
       "1                                     Patrick Li   \n",
       "2  Siraj Berhan, MBA, Certified Enterprise Coach   \n",
       "3                                     Ed Norrena   \n",
       "4                                  Natasha Walji   \n",
       "\n",
       "                                         role & firm  \\\n",
       "0  Digital Evangelist and Organization Evolution ...   \n",
       "1  Vice President Of Engineering at KioSoft Techn...   \n",
       "2  Director, Agile Enablement | Championing for a...   \n",
       "3  Pres and CEO at EDGE Environmental Consulting LTD   \n",
       "4  Director @ Google | McKinsey | Yale | Cambridg...   \n",
       "\n",
       "                       location  \\\n",
       "0     Oakville, Ontario, Canada   \n",
       "1  Greater Toronto Area, Canada   \n",
       "2      Toronto, Ontario, Canada   \n",
       "3       Ottawa, Ontario, Canada   \n",
       "4      Toronto, Ontario, Canada   \n",
       "\n",
       "                                               about  \\\n",
       "0  I have 21 years of experience in the transform...   \n",
       "1  Patrick's current focus is on coaching and tra...   \n",
       "2  Over 17 years of progressive software developm...   \n",
       "3  Ed Norrena is a civil engineer/executive with ...   \n",
       "4  Director at Google leading the Telecom, Tech &...   \n",
       "\n",
       "                                                urls  \n",
       "0  https://www.linkedin.com/sales/people/ACwAAADC...  \n",
       "1  https://www.linkedin.com/sales/people/ACwAAACT...  \n",
       "2  https://www.linkedin.com/sales/people/ACwAAAAT...  \n",
       "3  https://www.linkedin.com/sales/people/ACwAAAO4...  \n",
       "4  https://www.linkedin.com/sales/people/ACwAAAAG...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice that firm name usually comes after the key word \"at\"\n",
    "# so we can split our column role & firm using that information\n",
    "canada_prospects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Digital Evangelist and Organiz', 'ion Evolution Advisor']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of split\n",
    "canada_prospects['role & firm'].apply(lambda x: x.split('at'))[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
